{"cells":[{"metadata":{},"cell_type":"markdown","source":"Items to handle:\n* No seperate validation data given (**Solution:** using subset for trainingdata generation)\n* Elements in each catagores are different","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import image as mpimg\nimport seaborn as sns\n%matplotlib inline\nimport os\nimport random\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import RMSprop\nfrom   tensorflow.keras.preprocessing.image import img_to_array, load_img\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"character = mpimg.imread('../input/the-simpsons-characters-dataset/kaggle_simpson_testset/kaggle_simpson_testset/nelson_muntz_25.jpg')\nplt.imshow(character)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/the-simpsons-characters-dataset/simpsons_dataset/simpsons_dataset/'\ndir_df = pd.DataFrame({'class': [x for x in os.listdir(train_dir)]})\ncharacter_class = np.array(dir_df.sort_values(by=['class'], ascending = True))\ncharacter_class = character_class.reshape(42)\ncharacter_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = '../input/the-simpsons-characters-dataset/kaggle_simpson_testset/kaggle_simpson_testset/'\ntest_images = [x for x in os.walk(test_path)]\ntest_fnames = os.listdir( test_path )\ntest_fnames[:4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu',input_shape=(250,250,3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64,(3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(42,activation='softmax'),\n])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy']\n             )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Images Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(validation_split=0.3,\n                            rescale = 1.0/255.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = datagen.flow_from_directory(\n    directory=train_dir,\n    target_size=(250, 250),\n    color_mode=\"rgb\",\n    batch_size=20,\n    class_mode=\"categorical\",\n    subset='training', \n)\n\nvalidation_generator = datagen.flow_from_directory(\n    directory=train_dir,\n    target_size=(250, 250),\n    color_mode=\"rgb\",\n    batch_size=20,\n    class_mode=\"categorical\",\n    subset='validation',\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_generator,\n                    validation_data=validation_generator, \n                    steps_per_epoch=100,\n                    validation_steps=50,\n                    epochs=20,\n                    verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(history.history).plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image_files = [os.path.join(test_path, f) for f in test_fnames]\ntest_image_path = random.choice(test_image_files)\ntest_image = load_img(test_image_path, target_size=(250, 250))\nprint('Original toon name:','_'.join(test_image_path.split('/')[-1].split('.')[0].split('_')[:-1]))\nx   = img_to_array(test_image) \nx   = x.reshape((1,) + x.shape)\nx /= 255.0\ny_prob = model.predict(x) \ny_classes = y_prob.argmax()\nprint(\"Predicted toon name:\",character_class[y_classes])\nplt.imshow(test_image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_mached = 0 \nfailed_labels = []\nfor test_image in test_image_files:\n    org_label = '_'.join(test_image.split('/')[-1].split('_')[:-1])\n    test_img_load = load_img(test_image, target_size=(250,250))\n    \n    x = img_to_array(test_img_load)\n    x = x.reshape((1,) + x.shape)\n    x /= 255.0\n    y_prob = model.predict(x)\n    y_cls = y_prob.argmax()\n    pred_label = character_class[y_cls]\n    \n    if org_label == pred_label:\n        total_mached +=1\n    else:\n        failed_labels.append([org_label,pred_label,test_image])\n    \nprint('Total mached:', total_mached)\nprint('Test Accuracy:', total_mached/len(test_image_files))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(failed_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(failed_labels)):\n    character = mpimg.imread(falid_labels[i][2])\n    print(f'Original:{failed_labels[i][0]}, Predict: {failed_labels[i][1]}')\n    plt.imshow(character)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history.history[     'accuracy' ]\nval_acc  = history.history[ 'val_accuracy' ]\nloss     = history.history[    'loss' ]\nval_loss = history.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"successive_outputs = [layer.output for layer in model.layers[1:]]\nvisualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n\nimg_path = random.choice(test_image_files)\nimg = load_img(img_path, target_size=(250, 250))  # this is a PIL image\n\nx   = img_to_array(img)                           \nx   = x.reshape((1,) + x.shape)                   \nx /= 255.0\n\nsuccessive_feature_maps = visualization_model.predict(x)\nlayer_names = [layer.name for layer in model.layers]\n\n# -----------------------------------------------------------------------\n# Now let's display our representations\n# -----------------------------------------------------------------------\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n  \n  if len(feature_map.shape) == 4:\n    \n    #-------------------------------------------\n    # Just do this for the conv / maxpool layers, not the fully-connected layers\n    #-------------------------------------------\n    n_features = feature_map.shape[-1]  # number of features in the feature map\n    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n    \n    # We will tile our images in this matrix\n    display_grid = np.zeros((size, size * n_features))\n    \n    #-------------------------------------------------\n    # Postprocess the feature to be visually palatable\n    #-------------------------------------------------\n    for i in range(n_features):\n      x  = feature_map[0, :, :, i]\n      x -= x.mean()\n      x /= x.std ()\n      x *=  64\n      x += 128\n      x  = np.clip(x, 0, 255).astype('uint8')\n      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n\n    #-----------------\n    # Display the grid\n    #-----------------\n\n    scale = 20. / n_features\n    plt.figure( figsize=(scale * n_features, scale) )\n    plt.title ( layer_name )\n    plt.grid  ( False )\n    plt.imshow( display_grid, aspect='auto', cmap='viridis' ) \n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding Augmentation and Dropout","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2 = keras.Sequential([\n    keras.layers.Conv2D(32,(3,3), activation='relu', input_shape=(250,250,3)),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Conv2D(64,(3,3), activation='relu'),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Conv2D(128,(3,3), activation='relu'),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Conv2D(128,(3,3), activation='relu'),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Dropout(0.4),\n    keras.layers.Flatten(),\n    keras.layers.Dense(512, activation='relu'),\n    keras.layers.Dense(42, activation='softmax')\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy']\n             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen_2 = ImageDataGenerator(validation_split=0.3,\n                             rescale = 1.0/255.,\n                             rotation_range=40,\n                             width_shift_range=0.2,\n                             height_shift_range=0.2,\n                             shear_range=0.2,\n                             zoom_range=0.2,\n                             horizontal_flip=True,\n                             fill_mode='nearest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator_2 = datagen_2.flow_from_directory(\n    directory=train_dir,\n    target_size=(250, 250),\n    color_mode=\"rgb\",\n    batch_size=20,\n    class_mode=\"categorical\",\n    subset='training', \n)\n\nvalidation_generator_2 = datagen_2.flow_from_directory(\n    directory=train_dir,\n    target_size=(250, 250),\n    color_mode=\"rgb\",\n    batch_size=20,\n    class_mode=\"categorical\",\n    subset='validation',\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_2 = model_2.fit(train_generator_2,\n                    validation_data=validation_generator_2, \n                    steps_per_epoch=100,\n                    validation_steps=50,\n                    epochs=100,\n                    verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history_2.history['accuracy']\nval_acc = history_2.history['val_accuracy']\nloss = history_2.history['loss']\nval_loss = history_2.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image_files = [os.path.join(test_path, f) for f in test_fnames]\ntest_image_path = random.choice(test_image_files)\ntest_image = load_img(test_image_path, target_size=(250, 250))\nprint('Original toon name:','_'.join(test_image_path.split('/')[-1].split('.')[0].split('_')[:-1]))\nx   = img_to_array(test_image) \nx   = x.reshape((1,) + x.shape)\nx /= 255.0\ny_prob = model_2.predict(x) \ny_classes = y_prob.argmax()\nprint(\"Predicted toon name:\",character_class[y_classes])\nplt.imshow(test_image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_mached = 0 \nfailed_labels = []\nfor test_image in test_image_files:\n    org_label = '_'.join(test_image.split('/')[-1].split('_')[:-1])\n    test_img_load = load_img(test_image, target_size=(250,250))\n    \n    x = img_to_array(test_img_load)\n    x = x.reshape((1,) + x.shape)\n    x /= 255.0\n    y_prob = model_2.predict(x)\n    y_cls = y_prob.argmax()\n    pred_label = character_class[y_cls]\n    \n    if org_label == pred_label:\n        total_mached +=1\n    else:\n        failed_labels.append([org_label,pred_label,test_image])\n    \nprint('Total mached:', total_mached)\nprint('Test Accuracy:', total_mached/len(test_image_files))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(failed_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(failed_labels)):\n    character = mpimg.imread(failed_labels[i][2])\n    print(f'Original:{failed_labels[i][0]}, Predict: {failed_labels[i][1]}')\n    plt.imshow(character)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_2 = model_2.fit(train_generator_2,\n                    validation_data=validation_generator, \n                    steps_per_epoch=100,\n                    validation_steps=50,\n                    epochs=100,\n                    verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history_2.history['accuracy']\nval_acc = history_2.history['val_accuracy']\nloss = history_2.history['loss']\nval_loss = history_2.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image_files = [os.path.join(test_path, f) for f in test_fnames]\ntest_image_path = random.choice(test_image_files)\ntest_image = load_img(test_image_path, target_size=(250, 250))\nprint('Original toon name:','_'.join(test_image_path.split('/')[-1].split('.')[0].split('_')[:-1]))\nx   = img_to_array(test_image) \nx   = x.reshape((1,) + x.shape)\nx /= 255.0\ny_prob = model_2.predict(x) \ny_classes = y_prob.argmax()\nprint(\"Predicted toon name:\",character_class[y_classes])\nplt.imshow(test_image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_mached = 0 \nfailed_labels = []\nfor test_image in test_image_files:\n    org_label = '_'.join(test_image.split('/')[-1].split('_')[:-1])\n    test_img_load = load_img(test_image, target_size=(250,250))\n    \n    x = img_to_array(test_img_load)\n    x = x.reshape((1,) + x.shape)\n    x /= 255.0\n    y_prob = model_2.predict(x)\n    y_cls = y_prob.argmax()\n    pred_label = character_class[y_cls]\n    \n    if org_label == pred_label:\n        total_mached +=1\n    else:\n        failed_labels.append([org_label,pred_label,test_image])\n    \nprint('Total mached:', total_mached)\nprint('Test Accuracy:', total_mached/len(test_image_files))\nprint('Total miss classified:', len(failed_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(failed_labels)):\n    character = mpimg.imread(failed_labels[i][2])\n    print(f'Original:{failed_labels[i][0]}, Predict: {failed_labels[i][1]}')\n    plt.imshow(character)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen_3 = ImageDataGenerator(validation_split=0.3,\n                             rescale = 1.0/255.,\n                             rotation_range=15,\n                             width_shift_range=0.15,\n                             height_shift_range=0.15,\n                             shear_range=0.15,\n                             zoom_range=0.15,\n                             channel_shift_range=1,\n                             horizontal_flip=True,\n                             vertical_flip=True,\n                             fill_mode='nearest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}